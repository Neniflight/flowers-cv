{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714c1f41",
   "metadata": {},
   "source": [
    "# Flowers Classification Challenge with Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf20804",
   "metadata": {},
   "source": [
    "### Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "578596f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import PIL as image\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22b417",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c69124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data containing chi-squared distances\n",
    "#im unsure on how to use this in the context of computer vision\n",
    "dist_mat_data = scipy.io.loadmat('distancematrices102.mat')\n",
    "\n",
    "#contains label for each image\n",
    "label_data = scipy.io.loadmat('imagelabels.mat')\n",
    "\n",
    "#the indices for the splits between train, valid, and test\n",
    "split_data = scipy.io.loadmat('setid.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66fcc6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNX86, Created on: Thu Feb 19 17:38:58 2009',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'trnid': array([[6765, 6755, 6768, ..., 8026, 8036, 8041]], dtype=uint16),\n",
       " 'valid': array([[6773, 6767, 6739, ..., 8028, 8008, 8030]], dtype=uint16),\n",
       " 'tstid': array([[6734, 6735, 6737, ..., 8044, 8045, 8047]], dtype=uint16)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca405c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_data['trnid'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f22014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_data['valid'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed1781df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6149"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "although it is labeled tst, it has the most pictures in it, so ill assume this\n",
    "# is the training set\n",
    "\"\"\"\n",
    "len(split_data['tstid'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23de33e",
   "metadata": {},
   "source": [
    "Code below gets the indices for each image depending on whether it is train, test or valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2074a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 8185, 8187, 8188], dtype=uint16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices = np.unique(split_data['tstid'][0])\n",
    "train_indices = train_indices - 1\n",
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b8ce1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  27,   35,   78, ..., 8166, 8174, 8176], dtype=uint16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices = np.unique(split_data['trnid'][0])\n",
    "test_indices = test_indices - 1\n",
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4bbb20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  16,   22,   37, ..., 8181, 8184, 8186], dtype=uint16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices = np.unique(split_data['valid'][0])\n",
    "valid_indices = valid_indices - 1\n",
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dir contains all the images\n",
    "#valid, train, test_dir will contain the directories of images in respective\n",
    "# categories\n",
    "source_dir = 'jpg'\n",
    "valid_dir = 'valid'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa115cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 77, 77, ..., 62, 62, 62], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (label_data['labels'][0])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0c11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "valid_labels=[]\n",
    "test_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dff43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort images into their appropriate directories along with getting the proper labels\n",
    "image_files = os.listdir(source_dir)\n",
    "for i, filename in enumerate(image_files):\n",
    "    if i in train_indices:\n",
    "        shutil.move(os.path.join(source_dir, filename), os.path.join(train_dir, filename))\n",
    "        train_labels.append(labels[i])\n",
    "    elif i in test_indices:\n",
    "        shutil.move(os.path.join(source_dir, filename), os.path.join(test_dir, filename))\n",
    "        test_labels.append(labels[i])\n",
    "    elif i in valid_indices:\n",
    "        shutil.move(os.path.join(source_dir, filename), os.path.join(valid_dir, filename))\n",
    "        valid_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03be9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "valid_labels = np.array(valid_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34f7bd",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "580ad34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2202442a4f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(include_top=False, weights='imagenet', input_tensor=Input(shape=(224, 224, 3)))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5a838c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(102, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78cecd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c04c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba315d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
